{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0a02eff-ba56-4caa-bd7a-7dc3263a9055",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Running experiments in Azure Machine Learning\n",
    "\n",
    "In this lab, you will learn to run experiments in Azure Machine Learning from Azure Databricks. This lab will cover following exercises:\n",
    "\n",
    "- Exercise 1: Running an Azure ML experiment on Databricks\n",
    "- Exercise 2: Reviewing experiment metrics in Azure ML Studio\n",
    "\n",
    "To install the required libraries please follow the instructions in the lab guide.\n",
    "\n",
    "**Required Libraries**: \n",
    "* `azureml-sdk[databricks]` via PyPI\n",
    "* `sklearn-pandas==2.1.0` via PyPI\n",
    "* `azureml-mlflow` via PyPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b73f3be6-1e5e-4895-9208-c322686e3820",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Run the following cell to load common libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a97557e-e199-4aab-a4d1-0095a91b1ac6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": ""
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
        "text/plain": ""
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "3f3cc119-aaca1197916b7c051591ce2b"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\nFile \u001B[0;32m<command-1988255026187189>:14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleImputer\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StandardScaler, OneHotEncoder\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn_pandas\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataFrameMapper\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_squared_error, mean_absolute_error, r2_score\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py:171\u001B[0m, in \u001B[0;36m_create_import_patch.<locals>.import_patch\u001B[0;34m(name, globals, locals, fromlist, level)\u001B[0m\n\u001B[1;32m    166\u001B[0m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# Import the desired module. If you’re seeing this while debugging a failed import,\u001B[39;00m\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;66;03m# look at preceding stack frames for relevant error information.\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43mpython_builtin_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfromlist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m     is_root_import \u001B[38;5;241m=\u001B[39m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# `level` represents the number of leading dots in a relative import statement.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;66;03m# If it's zero, then this is an absolute import.\u001B[39;00m\n\n\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sklearn_pandas'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\nFile \u001B[0;32m<command-1988255026187189>:14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleImputer\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StandardScaler, OneHotEncoder\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn_pandas\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataFrameMapper\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_squared_error, mean_absolute_error, r2_score\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py:171\u001B[0m, in \u001B[0;36m_create_import_patch.<locals>.import_patch\u001B[0;34m(name, globals, locals, fromlist, level)\u001B[0m\n\u001B[1;32m    166\u001B[0m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# Import the desired module. If you’re seeing this while debugging a failed import,\u001B[39;00m\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;66;03m# look at preceding stack frames for relevant error information.\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43mpython_builtin_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfromlist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m     is_root_import \u001B[38;5;241m=\u001B[39m thread_local\u001B[38;5;241m.\u001B[39m_nest_level \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# `level` represents the number of leading dots in a relative import statement.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;66;03m# If it's zero, then this is an absolute import.\u001B[39;00m\n\n\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sklearn_pandas'",
       "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'sklearn_pandas'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import joblib\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "from azureml.core.model import Model\n",
    "\n",
    "print('The azureml.core version is {}'.format(azureml.core.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4787d4a6-92db-469b-b427-95c41dc26855",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Connect to the AML workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "080e5e04-10dd-418b-be96-79f048a2e7d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In the following cell, be sure to set the values for `subscription_id`, `resource_group`, and `workspace_name` as directed by the comments. Please note, you can copy the `subscription ID` and `resource group` name from the **Overview** page on the blade for the Azure ML workspace in the Azure portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "925c1b9c-0c80-4771-8171-a41cbf3b0498",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Provide the Subscription ID of your existing Azure subscription\n",
    "subscription_id = \"XXX-XXXX-XXXX-XXXX-XXXX\"\n",
    "\n",
    "#Replace the name below with the name of your resource group\n",
    "resource_group = \"XXX\"\n",
    "\n",
    "#Replace the name below with the name of your Azure Machine Learning workspace\n",
    "workspace_name = \"aml-ws\"\n",
    "\n",
    "print(\"subscription_id:\", subscription_id)\n",
    "print(\"resource_group:\", resource_group)\n",
    "print(\"workspace_name:\", workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea4e1c7e-3561-4bb1-9e27-f6b8343b136f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Important Note**: You will be prompted to login in the text that is output below the cell. Be sure to navigate to the URL displayed and enter the code that is provided. Once you have entered the code, return to this notebook and wait for the output to read `Workspace configuration succeeded`.\n",
    "\n",
    "*Also note that the sign-on link and code only appear the first time in a session. If an authenticated session is already established, you won't be prompted to enter the code and authenticate when creating an instance of the Workspace.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfd43933-a2bf-44a7-85ae-9dc0e9543982",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "print(ws)\n",
    "print('Workspace region:', ws.location)\n",
    "print('Workspace configuration succeeded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f0748e6-6339-4ad1-b1ee-6b3b6fdd7af4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load the training data\n",
    "\n",
    "In this notebook, we will be using a subset of NYC Taxi & Limousine Commission - green taxi trip records available from [Azure Open Datasets]( https://azure.microsoft.com/en-us/services/open-datasets/). The data is enriched with holiday and weather data. Each row of the table represents a taxi ride that includes columns such as number of passengers, trip distance, datetime information, holiday and weather information, and the taxi fare for the trip.\n",
    "\n",
    "Run the following cell to load the table into a Spark dataframe and reivew the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5864441e-83ed-4635-a8c5-04582b0c8f42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = spark.sql(\"select * from nyc_taxi\").toPandas()\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4bc4e7f-f07e-4fb3-afcc-0bc41ed81115",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exercise 1: Running an Azure ML experiment on Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "927480ac-0bb6-47b4-a73c-32fa1f4767c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Use MLflow with Azure Machine Learning for Model Training\n",
    "\n",
    "In the subsequent cells you will learn to do the following:\n",
    "- Set up MLflow tracking URI so as to use Azure ML\n",
    "- Create MLflow experiment – this will create a corresponding experiment in Azure ML Workspace\n",
    "- Train a model on Azure Databricks cluster while logging metrics and artifacts using MLflow\n",
    "\n",
    "After this notebook, you should return to the **lab guide** and follow instructions to review the model performance metrics and training artifacts in the Azure Machine Learning workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d084826f-4a0f-4e95-9019-06239533e0fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Set MLflow tracking URI\n",
    "\n",
    "Set the MLflow tracking URI to point to your Azure ML Workspace. The subsequent logging calls from MLflow APIs will go to Azure ML services and will be tracked under your Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "765a2d26-3878-4dc7-9c41-3492aa320611",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "print(\"MLflow tracking URI to point to your Azure ML Workspace setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a75e71c-0b52-4f87-a460-6a94511f70ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Configure experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97350f00-a7a8-4903-8f21-ad831cfd7ff6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_name = 'MLflow-AML-Exercise'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(\"Experiment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21e73871-736a-4ed3-8a55-7294d7dbfb3f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Train Model and Log Metrics and Artifacts\n",
    "\n",
    "Now you are ready to train the model. Run the cell below to do the following:\n",
    "-\tTrain model\n",
    "-\tEvaluate model\n",
    "-\tLog evaluation metrics\n",
    "-   Log artifact: Evaluation graph\n",
    "-   Save model\n",
    "-   Log artifact: Trained model\n",
    "\n",
    "Note that the metrics and artifacts will be saved in your `AML Experiment Run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17329841-a05a-4099-afff-7f6c95ecfaba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "output_folder = 'outputs'\n",
    "model_file_name = 'nyc-taxi.pkl'\n",
    "dbutils.fs.mkdirs(output_folder)\n",
    "model_file_path = os.path.join('/dbfs', output_folder, model_file_name)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "  df = dataset.dropna(subset=['totalAmount'])\n",
    "  x_df = df.drop(['totalAmount'], axis=1)\n",
    "  y_df = df['totalAmount']\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=0)\n",
    "\n",
    "  numerical = ['passengerCount', 'tripDistance', 'snowDepth', 'precipTime', 'precipDepth', 'temperature']\n",
    "  categorical = ['hour_of_day', 'day_of_week', 'month_num', 'normalizeHolidayName', 'isPaidTimeOff']\n",
    "\n",
    "  numeric_transformations = [([f], Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])) for f in numerical]\n",
    "    \n",
    "  categorical_transformations = [([f], OneHotEncoder(handle_unknown='ignore', sparse=False)) for f in categorical]\n",
    "\n",
    "  transformations = numeric_transformations + categorical_transformations\n",
    "\n",
    "  clf = Pipeline(steps=[('preprocessor', DataFrameMapper(transformations, df_out=True)), \n",
    "                        ('regressor', GradientBoostingRegressor())])\n",
    "\n",
    "  clf.fit(X_train, y_train)\n",
    "  \n",
    "  y_predict = clf.predict(X_test)\n",
    "  y_actual = y_test.values.flatten().tolist()\n",
    "  \n",
    "  rmse = math.sqrt(mean_squared_error(y_actual, y_predict))\n",
    "  mlflow.log_metric('rmse', rmse)\n",
    "  mae = mean_absolute_error(y_actual, y_predict)\n",
    "  mlflow.log_metric('mae', mae)\n",
    "  r2 = r2_score(y_actual, y_predict)\n",
    "  mlflow.log_metric('R2 score', r2)\n",
    "  \n",
    "  plt.figure(figsize=(10,10))\n",
    "  plt.scatter(y_actual, y_predict, c='crimson')\n",
    "  plt.yscale('log')\n",
    "  plt.xscale('log')\n",
    "\n",
    "  p1 = max(max(y_predict), max(y_actual))\n",
    "  p2 = min(min(y_predict), min(y_actual))\n",
    "  plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "  plt.xlabel('True Values', fontsize=15)\n",
    "  plt.ylabel('Predictions', fontsize=15)\n",
    "  plt.axis('equal')\n",
    "  \n",
    "  results_graph = os.path.join('/dbfs', output_folder, 'results.png')\n",
    "  plt.savefig(results_graph)\n",
    "  mlflow.log_artifact(results_graph)\n",
    "  \n",
    "  joblib.dump(clf, open(model_file_path,'wb'))\n",
    "  mlflow.log_artifact(model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12556aec-6ef5-43b8-8c18-df15ef12597d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### View the Experiment Run in Azure Machine Learning Workspace\n",
    "\n",
    "Run the cell below and then **right-click** on **Link to Azure Machine Learning studio** link below to open the `AML Experiment Run Details` page in a **new browser tab**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4531c990-6e47-40ac-b902-679014bdb0cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(ws.experiments[experiment_name].get_runs())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fd9da3d-0deb-48d7-bdbe-2a0a03e834fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exercise 2: Reviewing experiment metrics in Azure ML Studio\n",
    "\n",
    "Return to the `lab guide` and follow instructions to review the model performance metrics and training artifacts in the Azure Machine Learning workspace."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1.0 Running experiments in Azure Machine Learning",
   "notebookOrigID": 1988255026187154,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
